version: '3.8'

services:
  ollama:
    build:
      context: ./containers
      dockerfile: Dockerfile
    container_name: ollama
    environment:
      - OLLAMA_HOST=0.0.0.0:11434
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:11434/api/version']
      interval: 30s
      timeout: 10s
      retries: 3
    ports:
      - '11434:11434'
    networks:
      - ai-network

  backend:
    build:
      context: ./back-end
      dockerfile: Dockerfile
    container_name: backend
    ports:
      - '3000:3000'
    environment:
      - PORT=3000
      - OLLAMA_HOST=http://ollama:11434
    depends_on:
      ollama:
        condition: service_healthy
    networks:
      - ai-network

networks:
  ai-network:
    name: ai-network
